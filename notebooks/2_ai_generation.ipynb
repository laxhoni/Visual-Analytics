{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24744d9",
   "metadata": {},
   "source": [
    "# 2. AI Text generation (Generaci√≥n de texto artificial)\n",
    "\n",
    "* **Objetivo:** Crear el \"Dataset Sombra\" (Shadow Dataset).\n",
    "* **Estrategia:** Utilizar la API de **Google Gemini** para reescribir cada noticia del dataset humano original. El objetivo es mantener los hechos informativos pero alterar el estilo sint√°ctico y l√©xico para que refleje los patrones de una IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70694f42",
   "metadata": {},
   "source": [
    "## 2.1. Configuraci√≥n inicial\n",
    "\n",
    "Importamos las librer√≠as necesarias y definimos las constantes globales.\n",
    "* Definimos `INPUT_FILE` (la muestra humana creada en el Notebook 1) y `OUTPUT_FILE` (donde se guardar√° el dataset pareado de IA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32801fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import generativeai as genai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# API Key de Google Gemini (PERSONAL)\n",
    "GOOGLE_API_KEY = \"API_KEY_AQUI\"\n",
    "\n",
    "# Rutas de archivos\n",
    "INPUT_FILE = '../data/1_raw/all-the-news-5k-sample.csv'\n",
    "OUTPUT_FILE = '../data/3_synthetic/ai_generated_gemini.csv'\n",
    "\n",
    "# Crear carpeta de salida si no existe\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f17f1",
   "metadata": {},
   "source": [
    "## 2.2. Inicializaci√≥n del cliente Gemini\n",
    "\n",
    "Configuramos el cliente con la clave API y seleccionamos el modelo.\n",
    "Usamos **`gemini-2.0-flash`**, **`gemini-2.5-flash-lite-preview-09-2025`** por ser el modelo m√°s eficiente (r√°pido y gratuito) para tareas de reescritura masiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33242114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cliente Gemini configurado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Configurar la API\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-lite-preview-09-2025')\n",
    "\n",
    "print(\"‚úÖ Cliente Gemini configurado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f43291",
   "metadata": {},
   "source": [
    "## 2.3. Definici√≥n de la funci√≥n de reescritura\n",
    "\n",
    "Definimos la funci√≥n `rewrite_article`.\n",
    "* **Prompt Engineering:** Instruimos al modelo para que act√∫e como un \"Periodista IA\". Le pedimos expl√≠citamente que mantenga la informaci√≥n pero use su propio estilo.\n",
    "* **Limpieza:** Solicitamos que no a√±ada introducciones (\"Here is the text...\"), solo el cuerpo del art√≠culo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8af30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_article(text):\n",
    "    \"\"\"\n",
    "    Env√≠a el texto a Gemini para ser reescrito con estilo sint√©tico.\n",
    "    \"\"\"\n",
    "    # Prompt dise√±ado para imitar estilo period√≠stico artificial\n",
    "    prompt = f\"\"\"\n",
    "    Act as an AI journalist. Rewrite the following news article text.\n",
    "    Maintain the core information and facts, but use your own sentence structure and vocabulary.\n",
    "    Do not output any introduction like \"Here is the rewritten text\". Output ONLY the article body.\n",
    "    \n",
    "    Original Text:\n",
    "    {text[:8000]} \n",
    "    \"\"\"\n",
    "    \n",
    "    # Generaci√≥n de contenido\n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    # Retornamos el texto limpio\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f20b23",
   "metadata": {},
   "source": [
    "## 2.4. Bucle principal de generaci√≥n\n",
    "\n",
    "Iteramos sobre el dataset humano.\n",
    "1. Leemos el art√≠culo original.\n",
    "2. Lo enviamos a Gemini.\n",
    "3. Guardamos el resultado en una lista.\n",
    "4. Aplicamos un `time.sleep` para respetar los l√≠mites de velocidad de la versi√≥n gratuita de la API.\n",
    "\n",
    "Nota: Algunos de los art√≠culos (aprox. el 0.1%) no pueden ser reescritos por el LLM debido a la violaci√≥n de pol√≠ticas de contenido al tratarse de art√≠culos de √≠ndole sexual o violenta. Sin embargo, no supone ning√∫n problema, se filtrar√°n en el notebook 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13306626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Cargando datos humanos...\n",
      "üìä Total de art√≠culos a procesar: 5000\n",
      "üîÑ ARCHIVO DETECTADO: Ya existen 4344 art√≠culos procesados.\n",
      "‚ñ∂Ô∏è Iniciando trabajo... Faltan 656 art√≠culos.\n",
      "‚ö†Ô∏è Error en art√≠culo 2021: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
      "This appears to be caused by a blocked prompt, see `response.prompt_feedback`: block_reason: PROHIBITED_CONTENT\n",
      "\n",
      "   ... Procesados 4350/5000\n",
      "   ... Procesados 4360/5000\n",
      "   ... Procesados 4370/5000\n",
      "   ... Procesados 4380/5000\n",
      "   ... Procesados 4390/5000\n",
      "   ... Procesados 4400/5000\n",
      "   ... Procesados 4410/5000\n",
      "   ... Procesados 4420/5000\n",
      "   ... Procesados 4430/5000\n",
      "   ... Procesados 4440/5000\n",
      "   ... Procesados 4450/5000\n",
      "   ... Procesados 4460/5000\n",
      "   ... Procesados 4470/5000\n",
      "   ... Procesados 4480/5000\n",
      "   ... Procesados 4490/5000\n",
      "   ... Procesados 4500/5000\n",
      "   ... Procesados 4510/5000\n",
      "   ... Procesados 4520/5000\n",
      "   ... Procesados 4530/5000\n",
      "   ... Procesados 4540/5000\n",
      "   ... Procesados 4550/5000\n",
      "   ... Procesados 4560/5000\n",
      "   ... Procesados 4570/5000\n",
      "   ... Procesados 4580/5000\n",
      "   ... Procesados 4590/5000\n",
      "   ... Procesados 4600/5000\n",
      "   ... Procesados 4610/5000\n",
      "   ... Procesados 4620/5000\n",
      "   ... Procesados 4630/5000\n",
      "   ... Procesados 4640/5000\n",
      "   ... Procesados 4650/5000\n",
      "   ... Procesados 4660/5000\n",
      "   ... Procesados 4670/5000\n",
      "   ... Procesados 4680/5000\n",
      "   ... Procesados 4690/5000\n",
      "   ... Procesados 4700/5000\n",
      "‚ö†Ô∏è Error en art√≠culo 4705: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
      "This appears to be caused by a blocked prompt, see `response.prompt_feedback`: block_reason: PROHIBITED_CONTENT\n",
      "\n",
      "   ... Procesados 4710/5000\n",
      "   ... Procesados 4720/5000\n",
      "   ... Procesados 4730/5000\n",
      "   ... Procesados 4740/5000\n",
      "   ... Procesados 4750/5000\n",
      "   ... Procesados 4760/5000\n",
      "   ... Procesados 4770/5000\n",
      "   ... Procesados 4780/5000\n",
      "   ... Procesados 4790/5000\n",
      "   ... Procesados 4800/5000\n",
      "   ... Procesados 4810/5000\n",
      "   ... Procesados 4820/5000\n",
      "   ... Procesados 4830/5000\n",
      "   ... Procesados 4840/5000\n",
      "   ... Procesados 4850/5000\n",
      "   ... Procesados 4860/5000\n",
      "   ... Procesados 4870/5000\n",
      "   ... Procesados 4880/5000\n",
      "   ... Procesados 4890/5000\n",
      "   ... Procesados 4900/5000\n",
      "   ... Procesados 4910/5000\n",
      "   ... Procesados 4920/5000\n",
      "   ... Procesados 4930/5000\n",
      "   ... Procesados 4940/5000\n",
      "   ... Procesados 4950/5000\n",
      "   ... Procesados 4960/5000\n",
      "   ... Procesados 4970/5000\n",
      "   ... Procesados 4980/5000\n",
      "   ... Procesados 4990/5000\n",
      "   ... Procesados 5000/5000\n",
      "\n",
      "‚úÖ ¬°Proceso finalizado! Datos en: ../data/3_synthetic/ai_generated_gemini.csv\n"
     ]
    }
   ],
   "source": [
    "## 2.4. Bucle Principal (Con Diagn√≥stico)\n",
    "import os\n",
    "\n",
    "print(\"üöÄ Cargando datos humanos...\")\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    print(f\"‚ùå Error CR√çTICO: No encuentro el archivo {INPUT_FILE}\")\n",
    "else:\n",
    "    df_human = pd.read_csv(INPUT_FILE)\n",
    "    total_filas = len(df_human)\n",
    "    print(f\"üìä Total de art√≠culos a procesar: {total_filas}\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # L√ìGICA DE REANUDACI√ìN\n",
    "    # -----------------------------------------------------------\n",
    "    processed_ids = set()\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        try:\n",
    "            existing = pd.read_csv(OUTPUT_FILE)\n",
    "            # Solo si el archivo tiene datos y la columna correcta\n",
    "            if 'original_id' in existing.columns:\n",
    "                processed_ids = set(existing['original_id'].unique())\n",
    "                print(f\"üîÑ ARCHIVO DETECTADO: Ya existen {len(processed_ids)} art√≠culos procesados.\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è El archivo de salida existe pero no tiene la estructura correcta.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error leyendo archivo existente (se ignorar√°): {e}\")\n",
    "\n",
    "    # COMPROBACI√ìN DE SEGURIDAD\n",
    "    if len(processed_ids) >= total_filas:\n",
    "        print(\"\\nüõë ¬°ATENCI√ìN! El script se ha detenido porque PARECE QUE YA ACABASTE.\")\n",
    "        print(f\"   -> Filas totales: {total_filas}\")\n",
    "        print(f\"   -> Filas ya procesadas: {len(processed_ids)}\")\n",
    "        print(\"   ‚úÖ SOLUCI√ìN: Si quieres empezar de cero, BORRA el archivo:\")\n",
    "        print(f\"   rm {OUTPUT_FILE}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"‚ñ∂Ô∏è Iniciando trabajo... Faltan {total_filas - len(processed_ids)} art√≠culos.\")\n",
    "\n",
    "        # Header mode: Solo escribimos cabecera si el archivo NO existe\n",
    "        header_mode = not os.path.exists(OUTPUT_FILE)\n",
    "\n",
    "        for index, row in df_human.iterrows():\n",
    "            # 1. SALTAR YA PROCESADOS\n",
    "            if index in processed_ids:\n",
    "                continue\n",
    "\n",
    "            original_text = row['article']\n",
    "            \n",
    "            try:\n",
    "                # 2. LLAMADA A LA API\n",
    "                ai_text = rewrite_article(original_text)\n",
    "                \n",
    "                if ai_text:\n",
    "                    # 3. GUARDADO INCREMENTAL\n",
    "                    single_row = pd.DataFrame([{\n",
    "                        'original_id': index,\n",
    "                        'article': ai_text,\n",
    "                        'label': 1\n",
    "                    }])\n",
    "                    \n",
    "                    single_row.to_csv(OUTPUT_FILE, mode='a', header=header_mode, index=False)\n",
    "                    header_mode = False \n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error en art√≠culo {index}: {e}\")\n",
    "\n",
    "            # 4. PAUSA (IMPORTANTE)\n",
    "            time.sleep(4)\n",
    "            \n",
    "            # Feedback visual\n",
    "            if (index + 1) % 10 == 0:\n",
    "                print(f\"   ... Procesados {index + 1}/{total_filas}\")\n",
    "\n",
    "        print(f\"\\n‚úÖ ¬°Proceso finalizado! Datos en: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3eabb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "# CHECK LIST OF MODELS AVAILABLE\n",
    "models = genai.list_models()\n",
    "for m in models:\n",
    "    print(m.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
