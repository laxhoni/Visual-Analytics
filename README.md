# Analysis and evolution of language under the influence of content generated by artificial intelligence: A pilot study in the field of journalism

**Visual Analytics Final Project**
*Pompeu Fabra University Course - Fall 2025*

This project analyzes the "linguistic fingerprint" of AI-generated text compared to human-written news (pre-2020). It integrates **Machine Learning (XGBoost)**, **Explainable AI (SHAP)**, and an interactive **Streamlit Dashboard** to simulate how the widespread adoption of AI might influence the evolution of human language in journalism.

## ðŸ“‚ Project Structure

The repository is organized as follows:

```text
PROYECTO-FINAL-VISUAL-ANALYTICS/
â”‚
â”œâ”€â”€ data/                   # Local data storage (NOT synced to GitHub)
â”‚   â”œâ”€â”€ 01_raw/             # Original dataset (filtered 'All the News 2.0')
â”‚   â”œâ”€â”€ 02_processed/       # Cleaned data with calculated NLP metrics
â”‚   â””â”€â”€ 03_synthetic/       # AI-generated text (OpenAI API output)
â”‚
â”œâ”€â”€ notebooks/              # Jupyter Notebooks for experimentation
â”‚   â”œâ”€â”€ 1_data_filtering.ipynb     # Data loading, filtering (pre-2020), and sampling
â”‚   â”œâ”€â”€ 2_ai_generation.ipynb      # Script to generate synthetic text via OpenAI API
â”‚   â”œâ”€â”€ 3_feature_extraction.ipynb # NLP metrics calculation (Lexical diversity, Perplexity)
â”‚   â””â”€â”€ 4_model_training.ipynb     # XGBoost training & SHAP analysis
â”‚
â”œâ”€â”€ src/                    # Reusable source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ nlp_utils.py        # Functions for text cleaning and metric extraction
â”‚   â””â”€â”€ model_utils.py      # Functions to load/save models
â”‚
â”œâ”€â”€ app/                    # Streamlit Web Application (Final Deliverable)
â”‚   â”œâ”€â”€ main.py             # App entry point
â”‚   â”œâ”€â”€ pages/              # Additional dashboard pages
â”‚   â””â”€â”€ utils_viz.py        # Visualization functions (Altair/Plotly)
â”‚
â”œâ”€â”€ models/                 # Serialized trained models
â”‚   â”œâ”€â”€ xgboost_classifier.pkl
â”‚   â””â”€â”€ shap_explainer.pkl
â”‚
â”œâ”€â”€ reports/                # Documentation
â”‚   â””â”€â”€ final_report.pdf    # Final Project Report
â”‚
â”œâ”€â”€ .gitignore              # Git configuration (ignores data and secrets)
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation

